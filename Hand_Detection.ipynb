{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hand Detection using MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hand(path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image to RGB.\n",
    "\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "\n",
    "        h, w, c = image.shape \n",
    "        hand_landmarks = results.multi_hand_landmarks[0] \n",
    "        x_coords = [lm.x * w for lm in hand_landmarks.landmark]\n",
    "        y_coords = [lm.y * h for lm in hand_landmarks.landmark]\n",
    "        \n",
    "        x_min = int(min(x_coords))\n",
    "        x_max = int(max(x_coords))\n",
    "        y_min = int(min(y_coords))\n",
    "        y_max = int(max(y_coords))\n",
    "\n",
    "        margin = 150\n",
    "        hand_image = image[y_min-margin:y_max+margin, x_min-margin:x_max+margin]\n",
    "\n",
    "        hands.close()\n",
    "        return hand_image\n",
    "\n",
    "    else:\n",
    "        print(\"No hand detected.\")\n",
    "        hands.close()\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hand Processing using detect_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_color(hand_image,v=30):\n",
    "    \"\"\"\n",
    "    This is the original and more complex function for obtaining the mask of the hand. This function will be used to transform images\n",
    "    external to the dataset into photos similar to theones it used to train the model.\n",
    "    \"\"\"\n",
    "    bg = np.array(hand_image[0][:20])\n",
    "    analysis = st.mode(bg)\n",
    "\n",
    "    # Find the most popular color in the first 20\n",
    "    popular_color = analysis.mode\n",
    "\n",
    "    mask = np.ones((hand_image.shape[0],hand_image.shape[1]),dtype=np.uint8)\n",
    "    \n",
    "    high_cota = [min(255,popular_color[i]+v) for i in range(3)]\n",
    "    low_cota = [max(0,popular_color[i]-v) for i in range(3)]\n",
    "    for y,row in enumerate(hand_image):\n",
    "        for x,px in enumerate(row):\n",
    "            if (px[0]<=high_cota[0] and px[1]<=high_cota[1] and px[2]<=high_cota[2]) \\\n",
    "             and (px[0]>=low_cota[0] and px[1]>=low_cota[1] and px[2]>=low_cota[2]):\n",
    "                mask[y][x] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_processing(path):\n",
    "    hand_image = detect_hand(path)\n",
    "    if hand_image is not None:\n",
    "        if hand_image.shape[0] > 0:\n",
    "            mask = get_mask_color(hand_image, 30)\n",
    "\n",
    "            background_mask = cv2.bitwise_not(mask)\n",
    "            black_background = np.zeros_like(hand_image)\n",
    "\n",
    "            foreground = cv2.bitwise_and(hand_image, hand_image, mask=mask)\n",
    "            background = cv2.bitwise_and(black_background, black_background, mask=background_mask)\n",
    "\n",
    "            result = cv2.add(foreground, background)\n",
    "\n",
    "            height, width, _ = result.shape\n",
    "            square_size = max(height, width)\n",
    "\n",
    "            square_image = np.zeros((square_size, square_size, 3), dtype=np.uint8)\n",
    "            y_offset = (square_size - height) // 2\n",
    "            x_offset = (square_size - width) // 2\n",
    "            square_image[y_offset:y_offset + height, x_offset:x_offset + width] = result\n",
    "            resized_image = cv2.resize(square_image, (400, 400), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            \n",
    "            print('Hand detected in', path)\n",
    "            return resized_image\n",
    "\n",
    "    else:\n",
    "        #print('No hand detected in', filename)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Frame extraction and Hand Processing Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "base_folder = 'Images/' # Folder where the video is located\n",
    "video_name = 'cat' # Name of the video\n",
    "formato = '.mp4' # Format of the video\n",
    "final_folder = base_folder+\"Results/\" # Folder where the frames will be saved\n",
    "vidcap = cv2.VideoCapture('Images/'+video_name+formato)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "ratio = 2\n",
    "\n",
    "while success: # For all valid frames in the video, extract the hand and save it in the final folder\n",
    "    if count % ratio == 0:\n",
    "        cv2.imwrite(final_folder+\"frame%d.jpg\" % count, image)  # frame en carpeta\n",
    "    success,image = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every file in the folder try detecting its hand using the code above\n",
    "frames = []\n",
    "for filename in os.listdir(final_folder):\n",
    "    frames.append(hand_processing(os.path.join(final_folder, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,frame in enumerate(frames):\n",
    "    img_resized = Image.fromarray(frame)\n",
    "    img_resized.save(f\"frame{i}_processed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
